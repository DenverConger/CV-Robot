{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"personalproject.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPHofw2iA2vhgPH0Sld1kdY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"QjJ0k4N9ePIw","executionInfo":{"status":"ok","timestamp":1638335251345,"user_tz":420,"elapsed":2,"user":{"displayName":"Denver Conger","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIiKFGcKkHpjThzGvLJSmdRXrqtu4-lL9pn8yAAg=s64","userId":"08686499249180692673"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bSbFJuAfkRom"},"source":["# Camera Picture Generation"]},{"cell_type":"code","metadata":{"id":"hjDYyov2kRFT"},"source":["import time\n","import cv2\n","\n","pTime = 0\n","cTime = 0\n","cap = cv2.VideoCapture(1)\n","\n","cap.set(3,200)\n","\n","cap.set(4,200)\n","# cap.set(cv2.CAP_PROP_EXPOSURE,-6)\n","success, img = cap.read()\n","cv2.imshow(\"Image\", img)\n","cv2.waitKey(1)\n","i = 0\n","# while i <= 50:\n","while True:\n","    while i <= 400:\n","        success, img = cap.read()\n","\n","        cTime = time.time()\n","        fps = 1 / (cTime - pTime)\n","        pTime = cTime\n","\n","        cv2.imshow(\"Image\", img)\n","        cv2.waitKey(1)\n","        i+=1\n","        # cv2.putText(img, str(int(fps)), (50,50),3)\n","\n","        time.sleep(.1)\n","        print(f\"Photo Number {i}\")\n","        isWritten = cv2.imwrite(f'D:\\Coding\\ML\\_tictactoe\\O\\{i + 401}.png', img)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hxnUZUafkWZm"},"source":["# Model Stuff"]},{"cell_type":"code","metadata":{"id":"6JzUkTnve2Pt"},"source":["\n","from keras_preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications.vgg16 import VGG16\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Flatten\n","import pandas as pd\n","import numpy as np\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sn\n","from tensorflow.keras.optimizers import SGD\n","# config = tf2.ConfigProto()\n","# config.gpu_options.allow_growth = True\n","# session = tf2.InteractiveSession(config=config)\n","physical_devices = tf.config.list_physical_devices('GPU')\n","try:\n","  tf.config.set_logical_device_configuration(\n","    physical_devices[0],\n","    tf.config.LogicalDeviceConfiguration(memory_limit=4096))\n","\n","  logical_devices = tf.config.list_logical_devices('GPU')\n","  assert len(logical_devices) == len(physical_devices) + 1\n","\n","  tf.config.set_logical_device_configuration(\n","    physical_devices[0],\n","    tf.config.LogicalDeviceConfiguration(memory_limit=4096))\n","except:\n","#   # Invalid device or cannot modify logical devices once initialized.\n","  pass\n","opt = SGD(lr=0.001, momentum=0.9)\n","# adam = tf.keras.optimizers.Adam(\n","#     learning_rate= 0.02,\n","#     # epsilon=1e-08,\n","#     amsgrad=False,\n","#     name=\"adam\"\n","# )\n","def define_model():\n","    \n","\tmodel = VGG16(include_top=False, input_shape=(200, 200, 3))\n","\n","\tfor layer in model.layers:\n","\t\tlayer.trainable = False\n","\n","\tflattener = Flatten()(model.layers[-1].output)\n","\tlayer1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flattener)\n","\toutput = Dense(2, activation='softmax')(layer1)\n","\n","\tmodel = Model(inputs=model.inputs, outputs=output)\n","\tmodel.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n","\treturn model\n","\n","\n","def run():\n","\t# define model\n","    model = define_model()\n","        # create data generator\n","    print(\"train_dir\")\n","    training_dir = 'D:\\Coding\\AIsociety\\_tictactoe\\content\\\\training'\n","    image_size = (200, 200)\n","\n","    train_datagen = ImageDataGenerator(\n","            rescale=1./255,\n","            validation_split=.2,\n","            zoom_range=.2,\n","            rotation_range = 40,\n","            width_shift_range=0.2,\n","            height_shift_range=0.2,\n","            )\n","    validation_datagen = ImageDataGenerator(\n","            rescale=1./255,\n","            validation_split=.2,\n","            rotation_range = 40,\n","            width_shift_range=0.2,\n","            height_shift_range=0.2,\n","            )\n","\n","    train_generator = train_datagen.flow_from_directory(\n","            training_dir,\n","            target_size = image_size,\n","            subset=\"training\",\n","            batch_size=32,\n","            class_mode='sparse',\n","            seed=42,shuffle=True)\n","\n","    validation_generator = validation_datagen.flow_from_directory(\n","            training_dir,\n","            target_size=image_size,\n","            batch_size=32,\n","            class_mode='sparse',\n","            subset=\"validation\",\n","            seed=42)\n","    print(\"test_dir\")\n","    test_dir = 'D:\\Coding\\AIsociety\\_tictactoe\\content'\n","\n","    test_datagen = ImageDataGenerator(rescale=1./255,zoom_range=.2,\n","            rotation_range = 40,\n","            width_shift_range=0.2,\n","            height_shift_range=0.2)\n","    test_generator = test_datagen.flow_from_directory(\n","            test_dir,\n","            target_size=(200, 200),\n","            classes=['test'],\n","            class_mode='sparse',\n","            shuffle=False)\n","        # fit model\n","    history = model.fit(train_generator, steps_per_epoch=len(train_generator),\n","        validation_data=validation_generator, validation_steps=len(validation_generator), epochs=14, verbose=1)\n","    # evaluate model\n","    plt.plot(history.history['sparse_categorical_accuracy'])\n","    plt.plot(history.history['val_sparse_categorical_accuracy'])\n","    plt.title('model accuracy')\n","    plt.ylabel('accuracy')\n","    plt.xlabel('epoch')\n","    plt.legend(['train', 'val'], loc='upper left')\n","    plt.show()\n","\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    plt.title('model loss')\n","    plt.ylabel('loss')\n","    plt.xlabel('epoch')\n","    plt.legend(['train', 'val'], loc='upper left')\n","    plt.show()\n","\n","    base = pd.read_csv(\"D:\\Coding\\AIsociety\\_tictactoe\\content\\\\test_classes.csv\")\n","    base = base.ClassId\n","\n","\n","    pred = model.predict(test_generator, verbose=1)\n","\n","    cl = []\n","    for i in range(0, len(pred)):\n","        cl.append(np.argmax(pred[i]))\n","    cl = np.array(cl)\n","    print(cl[0])\n","    # for i in range(0,802):\n","    #     if cl[i] != base[i]:\n","    #         print(\"number\")\n","    #         print(i)\n","    #         print(\"cl\")\n","    #         print(cl[i])\n","    #         print(\"base\")\n","    #         print(base[i])\n","    Accuracy = accuracy_score(base, cl)\n","    \n","    print(\"accuracy on Test:\", Accuracy)\n","    from sklearn import metrics\n","    print(\"Accuracy:\",metrics.accuracy_score(base, cl))\n","    print(\"Recall: \", metrics.recall_score(base, cl, average='micro'))\n","\n","    cm = confusion_matrix(base,cl)\n","    df_cm = pd.DataFrame(cm, range(2), range(2))\n","    # plt.figure(figsize=(10,7))\n","    sn.set(font_scale=1.4) # for label size\n","    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n","\n","    plt.show()\n","    i = 0\n","    print(pred[i])\n","    plt.figure(figsize=(20,20))\n","    plt.subplot(1,2,1)\n","    plot_image(i, pred[i], base, gen_file(i))\n","    plt.subplot(1,2,2)\n","    plot_value_array(i, pred[i],  base)\n","    plt.show()\n","\n","    i = 1\n","    print(pred[i])\n","    plt.figure(figsize=(20,20))\n","    plt.subplot(1,2,1)\n","    plot_image(i, pred[i], base, gen_file(i))\n","    plt.subplot(1,2,2)\n","    plot_value_array(i, pred[i],  base)\n","    plt.show()\n","\n","run()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NUvsyZIMZGoI"},"source":["I built this to compare the VGG model"]},{"cell_type":"code","metadata":{"id":"XyEwqMCnfUex"},"source":["model = tf.keras.models.Sequential([\n","    # This is the first convolution\n","    tf.keras.layers.Conv2D(64, (3,3), activation=LeakyReLU(alpha=0.05), input_shape=(200,200,3),kernel_initializer = 'he_uniform')),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    # The second convolution\n","    tf.keras.layers.Conv2D(64, (3,3), activation=LeakyReLU(alpha=0.05),kernel_initializer = 'he_uniform')),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    # The third convolution\n","    tf.keras.layers.Conv2D(128, (3,3), activation=LeakyReLU(alpha=0.05),kernel_initializer = 'he_uniform')),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    # The fourth convolution\n","    tf.keras.layers.Conv2D(128, (3,3), activation=LeakyReLU(alpha=0.05),kernel_initializer = 'he_uniform')),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    # Flatten the results to feed into a DNN\n","    tf.keras.layers.Flatten(),\n","    # tf.keras.layers.Dropout(0.3),\n","    # 512 neuron hidden layer\n","    tf.keras.layers.Dense(512, activation=LeakyReLU(alpha=0.05)),\n","    # tf.keras.layers.Dropout(0.3),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VHOvZ0QLZM7t"},"source":["## Some Project code that this runs with to see Board_state"]},{"cell_type":"markdown","metadata":{"id":"mdJDzH7JZcbt"},"source":["This code is used to both see the grid, split the grid, and make sorted individual photos to send to the model"]},{"cell_type":"code","metadata":{"id":"hVE5IukSZMbx"},"source":["import cv2\n","import numpy as np\n","FILENAME = 'D:\\Coding\\pick.png'\n","def get_photo():\n","    cap = cv2.VideoCapture(1) # video capture source camera (Here webcam of laptop) \n","    while(True):\n","      ret,frame = cap.read()\n","      cv2.imshow('img1',frame) #display the captured image\n","      if cv2.waitKey(1) & 0xFF == ord('y'): #save on pressing 'y' \n","          cv2.imwrite(FILENAME,frame)\n","          cv2.destroyAllWindows()\n","          break\n","\n","    cap.release()\n","    return\n","get_photo()\n","\n","def blob_distance():\n","# (hMin = 163 , sMin = 59, vMin = 116), (hMax = 179 , sMax = 234, vMax = 255)\n","  img = cv2.imread(\"D:\\Coding\\pick.png\", cv2.IMREAD_COLOR)\n","  hMin = 163\n","  sMin = 59\n","  vMin = 116\n","\n","  hMax = 179\n","  sMax = 234\n","  vMax = 255\n","\n","  # Set minimum and max HSV values to display\n","  lower = np.array([hMin, sMin, vMin])\n","  upper = np.array([hMax, sMax, vMax])\n","  canvas = img.copy()\n","  # Create HSV Image and threshold into a range.\n","  hsv = cv2.cvtColor(canvas, cv2.COLOR_BGR2HSV)\n","  mask = cv2.inRange(hsv, lower, upper)\n","  mask = cv2.bitwise_not(mask)\n","  # blur = cv2.blur(mask, (5,5), 0)\n","  cv2.imshow(\"Mask\", mask)\n","  cv2.waitKey(0)\n","  cv2.destroyAllWindows()\n","  params = cv2.SimpleBlobDetector_Params()\n","\n","  params.minThreshold = 10\n","  params.maxThreshold = 200\n","\n","  # Filter by Area.\n","  params.filterByArea = True\n","  params.minArea = 10\n","\n","  # Filter by Circularity\n","  params.filterByCircularity = False\n","  params.minCircularity = 0.1\n","\n","  # Filter by Convexity\n","  params.filterByConvexity = False\n","  params.minConvexity = 0.87\n","\n","  # Filter by Inertia\n","  params.filterByInertia = False\n","  params.minInertiaRatio = 0.01\n","  detector = cv2.SimpleBlobDetector_create(params)\n","\n","  keypoints = detector.detect(mask)\n","  \n","  keys = cv2.drawKeypoints(img, keypoints, np.array([]),(0,0,255),cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n","  cv2.imshow(\"Keys\", keys)\n","  cv2.waitKey(0)\n","  cv2.destroyAllWindows()\n","  return keypoints\n","\n","\n","\n","def distance(kpt1, kpt2):\n","    #create numpy array with keypoint positions\n","    arr = np.array([kpt1.pt, kpt2.pt])\n","    # print(kpt1.pt)\n","    # print(kpt2.pt)\n","    #scale array to mm\n","    #return distance, calculted by pythagoras\n","    return np.sqrt(np.sum((arr[0]-arr[1])**2))\n","\n","\n","def area(keypoints):\n","  for i,keypoint in enumerate(keypoints[1:]):\n","      print(\"Distance: {0:6.3f}\".format(distance(keypoints[0], keypoint)))\n","  dist = distance(keypoints[0], keypoint)\n","  area = .5*(dist**2)\n","  return area\n","\n","\n","keypoints = blob_distance()\n","print(keypoints)\n","area(keypoints)\n","\n","\n","def grid(keypoints):\n","  \n","  image = FILENAME\n","  image = cv2.imread(image,cv2.IMREAD_COLOR)\n","  for i in enumerate(keypoints[1:]):\n","    dot_1 = keypoints[1].pt\n","    dot_2 = keypoints[0].pt\n","  print(\"dot_1\")\n","  print(dot_1)\n","  print(\"dot_2\")\n","  print(dot_2)\n","  lx = min[dot_1[0], dot_2[0]]\n","  ly = min[dot_1[1], dot_2[1]]\n","  lw = max[dot_1[0], dot_2[0]]\n","  lh = max[dot_1[1], dot_2[1]]\n","\n","  lx = int(lx)\n","  ly = int(ly)\n","\n","  lw = int(lw)\n","  lh = int(lh)\n","  # lx = int(dot_1[0])\n","  # ly = int(dot_1[1])\n","\n","  # lw = int(dot_2[0])\n","  # lh = int(dot_2[1])\n","  print('lx,ly,lw,lh')\n","  print(lx,ly,lw,lh)\n","\n","\n","  print('lx,ly,lw,lh')\n","  print(lx,ly,lw,lh)\n","  rect = cv2.rectangle(image, (lx,ly), (lw,lh), (255, 255, 0), 5, cv2.LINE_AA)\n","  print(rect)\n","  largest = image[ly:lh, lw:lx]\n","  print(largest.shape)\n","  \n","  \n","  # ret, img = image.read()\n","  # cv2.imshow('img', img)\n","  # k = cv2.waitKey(30) & 0xff\n","  # if k == 27:\n","  #     break\n","  # ret, image = img.read()\n","\n","  gray = cv2.cvtColor(largest, cv2.COLOR_BGR2GRAY)\n","  # cv2.imshow(\"gray\", gray)\n","\n","  blur = cv2.GaussianBlur(gray, (5,5), 0)\n","  # cv2.imshow(\"blur\", blur)\n","\n","  thresh = cv2.adaptiveThreshold(blur, 255, 1, 1, 11, 2)\n","  # cv2.imshow(\"thresh\", thresh)\n","\n","  contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","\n","\n","  big = max(contours, key = cv2.contourArea)\n","  print('big.shape')\n","  print(big.shape)\n","  largest_area = cv2.contourArea(big)\n","  print(largest_area)\n","\n","  bx,by,bw,bh = cv2.boundingRect(big)\n","  print(\"bx,by,bw,bh\")\n","  print(bx,by,bw,bh)\n","  biggest = largest[by:by+bh, bx:bx+bw]\n","  print('biggest.shape')\n","  print(biggest.shape)\n","  print('[by,by+bh]')\n","  print([by,bh])\n","  print('bx,bx+bw')\n","  print(bx,bw)\n","  cv2.rectangle(largest, (bx,by), (bx+bw, by+bh), (0, 255, 0), 2, cv2.LINE_AA)\n","  c = 0\n","  n = 0\n","  for i in contours:\n","          # x,y,w,h = cv2.boundingRect(i)\n","          # if x < bx and (((w)*3)/(bw) < 1) and (((w)*3)/(bw) > .8):\n","          area = cv2.contourArea(i)\n","          if area >= (largest_area / 13) and area <= (largest_area / 6):\n","            x,y,w,h = cv2.boundingRect(i)\n","            cv2.putText(largest, f'{8-n}', (int(x+(w/2-5)),int(y+(h/2))), cv2.FONT_HERSHEY_DUPLEX, .4, color=(255, 0, 0) )\n","            cropped = largest[y:y+h, x:x+w]\n","\n","            cv2.imshow(f\"Crop{8-n}\", cropped)\n","            cv2.imwrite(f'D:\\Coding\\AIsociety\\_tictactoe\\Matrix-{8-n}.png', cropped)\n","\n","            cv2.rectangle(largest, (x,y), (x+w, y+h), (0, 255, 0), 2, cv2.LINE_AA)\n","            n+=1   \n","            c+=1\n","  # cv2.drawContours(img, contours, -1, (0, 255, 0), 3)\n","  cv2.imshow(\"Image\", largest)\n","  cv2.waitKey(0)\n","  cv2.destroyAllWindows()\n","    # if cv2.waitKey(1) & 0xFF == ord('q'):\n","    #       break\n","grid(keypoints)"],"execution_count":null,"outputs":[]}]}